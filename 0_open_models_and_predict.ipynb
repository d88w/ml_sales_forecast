{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "from datetime import date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the models from disk\n",
    "\n",
    "filename1 = 'sales_fcst_rf.sav'\n",
    "rf = pickle.load(open(filename1, 'rb'))\n",
    "\n",
    "filename2 = 'sales_fcst_rf_intl_together.sav'\n",
    "rf_int_t = pickle.load(open(filename2, 'rb'))\n",
    "\n",
    "filename3 = 'sales_fcst_gb.sav'\n",
    "gb = pickle.load(open(filename3, 'rb'))\n",
    "\n",
    "filename4 = 'sales_fcst_gb_intl_together.sav'\n",
    "gb_int_t = pickle.load(open(filename4, 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "redshift_endpoint = 'bi-dw-instance.cqutp4iwqhnr.us-east-1.redshift.amazonaws.com'\n",
    "redshift_user = 'ds_derek'\n",
    "redshift_pass = 'Z00mdwh36762'\n",
    "port = 5439\n",
    "dbname = 'zoomdwhdb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text\n",
    "engine_string = \"postgresql+psycopg2://%s:%s@%s:%d/%s\" \\\n",
    "% (redshift_user, redshift_pass, redshift_endpoint, port, dbname)\n",
    "engine = create_engine(engine_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "-----------\n",
    "-----------\n",
    "-----------\n",
    "----------- TESTING\n",
    "-----------\n",
    "-----------\n",
    "-----------\n",
    "\n",
    "\n",
    "WITH a AS \n",
    "--- Opportunities\n",
    "(SELECT a.dt,\n",
    "       c.fy_quarter,\n",
    "       a.dt - c.qtr_start + 1 AS day_of_qtr,\n",
    "       case when d.sales_div_clean is null then 'UnDefined' else d.sales_div_clean end AS sales_div,\n",
    "       SUM(CASE WHEN a.stagename = '1. Qualification' THEN 1 ELSE 0 END) AS stage_1_count,\n",
    "       SUM(CASE WHEN a.stagename = '1. Qualification' THEN a.amount_usd ELSE 0 END) AS stage_1_amount,\n",
    "       SUM(CASE WHEN a.stagename = '2. Discovery' THEN 1 ELSE 0 END) AS stage_2_count,\n",
    "       SUM(CASE WHEN a.stagename = '2. Discovery' THEN a.amount_usd ELSE 0 END) AS stage_2_amount,\n",
    "       SUM(CASE WHEN a.stagename = '3. Solution' THEN 1 ELSE 0 END) AS stage_3_count,\n",
    "       SUM(CASE WHEN a.stagename = '3. Solution' THEN a.amount_usd ELSE 0 END) AS stage_3_amount,\n",
    "       SUM(CASE WHEN a.stagename = '4. POC' THEN 1 ELSE 0 END) AS stage_4_count,\n",
    "       SUM(CASE WHEN a.stagename = '4. POC' THEN a.amount_usd ELSE 0 END) AS stage_4_amount,\n",
    "       SUM(CASE WHEN a.stagename = '5. Contract' THEN 1 ELSE 0 END) AS stage_5_count,\n",
    "       SUM(CASE WHEN a.stagename = '5. Contract' THEN a.amount_usd ELSE 0 END) AS stage_5_amount,\n",
    "       SUM(CASE WHEN a.stagename IN ('3. Solution','4. POC','5. Contract') and a.amount_usd > 10000 THEN a.amount_usd ELSE 0 END) stage345_large_deals,\n",
    "       SUM(CASE WHEN a.stagename IN ('4. POC','5. Contract') and a.amount_usd > 10000 THEN a.amount_usd ELSE 0 END) stage45_large_deals,\n",
    "       SUM(CASE WHEN a.stagename IN ('5. Contract') and a.amount_usd > 10000 THEN a.amount_usd ELSE 0 END) stage5_large_deals\n",
    "FROM  (SELECT a.*, b.rate, a.amount / b.rate AS amount_usd ------ opps in USD\n",
    "        FROM src_sfdc.opportunity_history a\n",
    "        LEFT JOIN src_zuora.currency b ON (case when a.currencyisocode is null then 'USD' else a.currencyisocode end) = b.alphabeticcode\n",
    "        where a.dt - a.lastactivitydate::date < 120 --- only opps that were touched within 120 days\n",
    "        ) a \n",
    "  LEFT JOIN src_sfdc.account b ON a.accountid = b.id\n",
    "  LEFT JOIN src_config.zoom_quarter_mapping c\n",
    "         ON a.dt BETWEEN c.qtr_start\n",
    "        AND c.qtr_end\n",
    "  LEFT JOIN lab.dw_20190311_sales_owner_division_clean_up d ON a.owner_division__c = d.sales_div_dirty\n",
    "WHERE 1 = 1\n",
    "AND   a.isdeleted = FALSE\n",
    "AND   a.isclosed = FALSE\n",
    "AND   a.amount_usd > 0\n",
    "AND   a.closedate between c.qtr_start AND c.qtr_end ---- only opps closing from the given quarter\n",
    "AND   a.dt >= (SELECT qtr_start\n",
    "             FROM src_config.zoom_quarter_mapping\n",
    "             WHERE CURRENT_DATE BETWEEN qtr_start AND qtr_end)\n",
    "GROUP BY 1,\n",
    "         2,\n",
    "         3,\n",
    "         4),\n",
    "         \n",
    "b AS\n",
    "---- QTD bookings\n",
    "(SELECT booking_date__c as dt,\n",
    "       fy_quarter,\n",
    "       case when sales_div_clean is null then 'UnDefined' else sales_div_clean end as sales_div,\n",
    "       SUM(bookings) OVER (PARTITION BY fy_quarter, sales_div_clean ORDER BY booking_date__c ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS bookings_qtd\n",
    "FROM (SELECT a.booking_date__c,\n",
    "             b.fy_quarter,\n",
    "             c.sales_div_clean,\n",
    "             SUM(Amount__c) AS bookings\n",
    "      FROM src_sfdc.bookings a\n",
    "        LEFT JOIN src_config.zoom_quarter_mapping b\n",
    "               ON a.booking_date__c BETWEEN b.qtr_start\n",
    "              AND b.qtr_end\n",
    "        LEFT JOIN lab.dw_20190311_sales_owner_division_clean_up c ON a.owner_division__c = c.sales_div_dirty\n",
    "      WHERE 1 = 1\n",
    "      AND   isdeleted = FALSE\n",
    "      AND   ((Order_Type__c IN ('New','New Order') AND Amount__c >= 17) \n",
    "            OR (Order_Type__c = 'Upsell' AND Amount__c >= 0) \n",
    "            OR (Order_Type__c IN ('New','New Order') AND Amount__c < 17 AND Coupon__c <> '' AND coupon__c IS NOT NULL) \n",
    "            OR (bookingexception__c = 'Y'))\n",
    "      AND   LOWER(owner_name) NOT LIKE '%integration%'\n",
    "      AND   account__c <> ''\n",
    "      AND   account__c IS NOT NULL\n",
    "      AND   a.booking_date__c >= '2018-02-01'\n",
    "      AND   a.booking_date__c >= (SELECT qtr_start\n",
    "                                FROM src_config.zoom_quarter_mapping\n",
    "                                WHERE CURRENT_DATE BETWEEN qtr_start AND qtr_end)\n",
    "      GROUP BY 1,\n",
    "               2,\n",
    "               3)\n",
    "ORDER BY 3,1),\n",
    "\n",
    "c AS\n",
    "---- Bookings total for the quarter\n",
    "(SELECT b.fy_quarter,\n",
    "       case when c.sales_div_clean is null then 'UnDefined' else c.sales_div_clean end as sales_div,\n",
    "       SUM(Amount__c) AS direct_bookings\n",
    "FROM src_sfdc.bookings a\n",
    "  LEFT JOIN src_config.zoom_quarter_mapping b\n",
    "         ON a.booking_date__c BETWEEN b.qtr_start\n",
    "        AND b.qtr_end\n",
    "  LEFT JOIN lab.dw_20190311_sales_owner_division_clean_up c ON a.owner_division__c = c.sales_div_dirty\n",
    "WHERE 1 = 1\n",
    "AND   isdeleted = FALSE\n",
    "AND   ((Order_Type__c IN ('New','New Order') AND Amount__c >= 17) \n",
    "      OR (Order_Type__c = 'Upsell' AND Amount__c >= 0) \n",
    "      OR (Order_Type__c IN ('New','New Order') AND Amount__c < 17 AND Coupon__c <> '' AND coupon__c IS NOT NULL) \n",
    "      OR (bookingexception__c = 'Y'))\n",
    "AND   lower(owner_name) NOT LIKE '%integration%'\n",
    "AND   account__c <> ''\n",
    "AND   account__c IS NOT NULL\n",
    "AND   a.booking_date__c >= '2018-02-01'\n",
    "AND   a.booking_date__c >= (SELECT qtr_start\n",
    "                          FROM src_config.zoom_quarter_mapping\n",
    "                          WHERE CURRENT_DATE BETWEEN qtr_start AND qtr_end)\n",
    "GROUP BY 1,2\n",
    "ORDER BY 1,2),\n",
    "\n",
    "d AS\n",
    "(SELECT b.fy_quarter,\n",
    "       case when c.sales_div_clean is null then 'UnDefined' else c.sales_div_clean end as sales_div,\n",
    "       SUM(quota__c) AS quota\n",
    "FROM src_sfdc.quota a\n",
    "  LEFT JOIN src_config.zoom_quarter_mapping b ON a.start_date__c::date = b.qtr_start\n",
    "  LEFT JOIN lab.dw_20190311_sales_owner_division_clean_up c ON a.email__c = c.sales_div_dirty\n",
    "WHERE quota_owner_type__c = 'Segment'\n",
    "and quota__c > 0\n",
    "GROUP BY 1,2)\n",
    "\n",
    "SELECT a.dt,\n",
    "       a.fy_quarter,\n",
    "       a.day_of_qtr,\n",
    "       a.sales_div,\n",
    "       d.quota,\n",
    "       a.stage_1_count,\n",
    "       a.stage_1_amount,\n",
    "       a.stage_2_count,\n",
    "       a.stage_2_amount,\n",
    "       a.stage_3_count,\n",
    "       a.stage_3_amount,\n",
    "       a.stage_4_count,\n",
    "       a.stage_4_amount,\n",
    "       a.stage_5_count,\n",
    "       a.stage_5_amount,\n",
    "       CASE WHEN b.bookings_qtd IS NULL AND MAX(b.bookings_qtd) OVER (PARTITION BY a.fy_quarter, a.sales_div ORDER BY a.sales_div, a.dt ROWS BETWEEN 30 PRECEDING AND CURRENT ROW) IS NULL THEN 0\n",
    "            WHEN b.bookings_qtd IS NULL THEN MAX(b.bookings_qtd) OVER (PARTITION BY a.fy_quarter, a.sales_div ORDER BY a.sales_div, a.dt ROWS BETWEEN 30 PRECEDING AND CURRENT ROW) \n",
    "            ELSE b.bookings_qtd END as bookings_qtd,\n",
    "       c.direct_bookings,\n",
    "       case when a.fy_quarter like '%Q1' then a.day_of_qtr::float / 89 else a.day_of_qtr::float / 92 end as qtr_pct,\n",
    "       a.stage_1_amount / d.quota AS s1_quota_ratio,\n",
    "       a.stage_2_amount / d.quota AS s2_quota_ratio,\n",
    "       a.stage_3_amount / d.quota AS s3_quota_ratio,\n",
    "       a.stage_4_amount / d.quota AS s4_quota_ratio,\n",
    "       a.stage_5_amount / d.quota AS s5_quota_ratio,\n",
    "       (a.stage_1_amount + a.stage_2_amount + a.stage_3_amount + a.stage_4_amount + a.stage_5_amount +      \n",
    "            CASE WHEN b.bookings_qtd IS NULL AND MAX(b.bookings_qtd) OVER (PARTITION BY a.fy_quarter, a.sales_div ORDER BY a.sales_div, a.dt ROWS BETWEEN 30 PRECEDING AND CURRENT ROW) IS NULL THEN 0\n",
    "                 WHEN b.bookings_qtd IS NULL THEN MAX(b.bookings_qtd) OVER (PARTITION BY a.fy_quarter, a.sales_div ORDER BY a.sales_div, a.dt ROWS BETWEEN 30 PRECEDING AND CURRENT ROW) \n",
    "                 ELSE b.bookings_qtd END )/ d.quota AS s12345_bk_qtd_quota_ratio,\n",
    "       (a.stage_2_amount + a.stage_3_amount + a.stage_4_amount + a.stage_5_amount +      \n",
    "            CASE WHEN b.bookings_qtd IS NULL AND MAX(b.bookings_qtd) OVER (PARTITION BY a.fy_quarter, a.sales_div ORDER BY a.sales_div, a.dt ROWS BETWEEN 30 PRECEDING AND CURRENT ROW) IS NULL THEN 0\n",
    "                 WHEN b.bookings_qtd IS NULL THEN MAX(b.bookings_qtd) OVER (PARTITION BY a.fy_quarter, a.sales_div ORDER BY a.sales_div, a.dt ROWS BETWEEN 30 PRECEDING AND CURRENT ROW) \n",
    "                 ELSE b.bookings_qtd END )/ d.quota AS s2345_bk_qtd_quota_ratio,\n",
    "       (a.stage_3_amount + a.stage_4_amount + a.stage_5_amount +      \n",
    "            CASE WHEN b.bookings_qtd IS NULL AND MAX(b.bookings_qtd) OVER (PARTITION BY a.fy_quarter, a.sales_div ORDER BY a.sales_div, a.dt ROWS BETWEEN 30 PRECEDING AND CURRENT ROW) IS NULL THEN 0\n",
    "                 WHEN b.bookings_qtd IS NULL THEN MAX(b.bookings_qtd) OVER (PARTITION BY a.fy_quarter, a.sales_div ORDER BY a.sales_div, a.dt ROWS BETWEEN 30 PRECEDING AND CURRENT ROW) \n",
    "                 ELSE b.bookings_qtd END )/ d.quota AS s345_bk_qtd_quota_ratio,\n",
    "       (a.stage_4_amount + a.stage_5_amount +      \n",
    "            CASE WHEN b.bookings_qtd IS NULL AND MAX(b.bookings_qtd) OVER (PARTITION BY a.fy_quarter, a.sales_div ORDER BY a.sales_div, a.dt ROWS BETWEEN 30 PRECEDING AND CURRENT ROW) IS NULL THEN 0\n",
    "                 WHEN b.bookings_qtd IS NULL THEN MAX(b.bookings_qtd) OVER (PARTITION BY a.fy_quarter, a.sales_div ORDER BY a.sales_div, a.dt ROWS BETWEEN 30 PRECEDING AND CURRENT ROW) \n",
    "                 ELSE b.bookings_qtd END )/ d.quota AS s45_bk_qtd_quota_ratio,\n",
    "       (a.stage_5_amount +      \n",
    "            CASE WHEN b.bookings_qtd IS NULL AND MAX(b.bookings_qtd) OVER (PARTITION BY a.fy_quarter, a.sales_div ORDER BY a.sales_div, a.dt ROWS BETWEEN 30 PRECEDING AND CURRENT ROW) IS NULL THEN 0\n",
    "                 WHEN b.bookings_qtd IS NULL THEN MAX(b.bookings_qtd) OVER (PARTITION BY a.fy_quarter, a.sales_div ORDER BY a.sales_div, a.dt ROWS BETWEEN 30 PRECEDING AND CURRENT ROW) \n",
    "                 ELSE b.bookings_qtd END )/ d.quota AS s5_bk_qtd_quota_ratio,\n",
    "\n",
    "       (a.stage345_large_deals / d.quota) AS s345_lg_deal_quota_ratio,\n",
    "       (a.stage45_large_deals / d.quota) AS s45_lg_deal_quota_ratio,\n",
    "       (a.stage5_large_deals / d.quota) AS s5_lg_deal_quota_ratio,\n",
    "\n",
    "       (CASE WHEN b.bookings_qtd IS NULL AND MAX(b.bookings_qtd) OVER (PARTITION BY a.fy_quarter, a.sales_div ORDER BY a.sales_div, a.dt ROWS BETWEEN 30 PRECEDING AND CURRENT ROW) IS NULL THEN 0\n",
    "                 WHEN b.bookings_qtd IS NULL THEN MAX(b.bookings_qtd) OVER (PARTITION BY a.fy_quarter, a.sales_div ORDER BY a.sales_div, a.dt ROWS BETWEEN 30 PRECEDING AND CURRENT ROW) \n",
    "                 ELSE b.bookings_qtd END ) / d.quota as bookings_pct_qtd,\n",
    "       c.direct_bookings / d.quota as bookings_pct_finish\n",
    "FROM a\n",
    "  LEFT JOIN b\n",
    "         ON a.dt = b.dt\n",
    "        AND a.sales_div = b.sales_div\n",
    "        AND a.fy_quarter = b.fy_quarter\n",
    "  LEFT JOIN c\n",
    "         ON a.sales_div = c.sales_div\n",
    "        AND a.fy_quarter = c.fy_quarter\n",
    "  LEFT JOIN d\n",
    "         ON a.sales_div = d.sales_div\n",
    "        AND a.fy_quarter = d.fy_quarter\n",
    "WHERE a.dt >= (SELECT qtr_start\n",
    "                          FROM src_config.zoom_quarter_mapping\n",
    "                          WHERE CURRENT_DATE BETWEEN qtr_start AND qtr_end)\n",
    "AND a.sales_div NOT IN ('Channel', 'ISV', 'Online Team', 'UnDefined', 'API')\n",
    "ORDER BY 4,1,2,3;'''\n",
    "raw_data = pd.read_sql_query(text(sql), engine)\n",
    "raw_data.to_csv(\"/Users/derekwang/Desktop/Python/Sales Forecast/data_testing_curr_quarter.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "-----------\n",
    "-----------\n",
    "-----------\n",
    "----------- TESTING\n",
    "-----------\n",
    "-----------\n",
    "-----------\n",
    "\n",
    "\n",
    "WITH a AS \n",
    "--- Opportunities\n",
    "(SELECT a.dt,\n",
    "       c.fy_quarter,\n",
    "       a.dt - c.qtr_start + 1 AS day_of_qtr,\n",
    "       case when d.sales_div_clean is null then 'UnDefined' else d.sales_div_clean end AS sales_div,\n",
    "       SUM(CASE WHEN a.stagename = '1. Qualification' THEN 1 ELSE 0 END) AS stage_1_count,\n",
    "       SUM(CASE WHEN a.stagename = '1. Qualification' THEN a.amount_usd ELSE 0 END) AS stage_1_amount,\n",
    "       SUM(CASE WHEN a.stagename = '2. Discovery' THEN 1 ELSE 0 END) AS stage_2_count,\n",
    "       SUM(CASE WHEN a.stagename = '2. Discovery' THEN a.amount_usd ELSE 0 END) AS stage_2_amount,\n",
    "       SUM(CASE WHEN a.stagename = '3. Solution' THEN 1 ELSE 0 END) AS stage_3_count,\n",
    "       SUM(CASE WHEN a.stagename = '3. Solution' THEN a.amount_usd ELSE 0 END) AS stage_3_amount,\n",
    "       SUM(CASE WHEN a.stagename = '4. POC' THEN 1 ELSE 0 END) AS stage_4_count,\n",
    "       SUM(CASE WHEN a.stagename = '4. POC' THEN a.amount_usd ELSE 0 END) AS stage_4_amount,\n",
    "       SUM(CASE WHEN a.stagename = '5. Contract' THEN 1 ELSE 0 END) AS stage_5_count,\n",
    "       SUM(CASE WHEN a.stagename = '5. Contract' THEN a.amount_usd ELSE 0 END) AS stage_5_amount,\n",
    "       SUM(CASE WHEN a.stagename IN ('3. Solution','4. POC','5. Contract') and a.amount_usd > 10000 THEN a.amount_usd ELSE 0 END) stage345_large_deals,\n",
    "       SUM(CASE WHEN a.stagename IN ('4. POC','5. Contract') and a.amount_usd > 10000 THEN a.amount_usd ELSE 0 END) stage45_large_deals,\n",
    "       SUM(CASE WHEN a.stagename IN ('5. Contract') and a.amount_usd > 10000 THEN a.amount_usd ELSE 0 END) stage5_large_deals\n",
    "FROM  (SELECT a.*, b.rate, a.amount / b.rate AS amount_usd ------ opps in USD\n",
    "        FROM src_sfdc.opportunity_history a\n",
    "        LEFT JOIN src_zuora.currency b ON (case when a.currencyisocode is null then 'USD' else a.currencyisocode end) = b.alphabeticcode\n",
    "        where a.dt - a.lastactivitydate::date < 120 --- only opps that were touched within 120 days\n",
    "        ) a \n",
    "  LEFT JOIN src_sfdc.account b ON a.accountid = b.id\n",
    "  LEFT JOIN src_config.zoom_quarter_mapping c\n",
    "         ON a.dt BETWEEN c.qtr_start\n",
    "        AND c.qtr_end\n",
    "  LEFT JOIN lab.dw_20190311_sales_owner_division_clean_up_intl_as_one d ON a.owner_division__c = d.sales_div_dirty\n",
    "WHERE 1 = 1\n",
    "AND   a.isdeleted = FALSE\n",
    "AND   a.isclosed = FALSE\n",
    "AND   a.amount_usd > 0\n",
    "AND   a.closedate between c.qtr_start AND c.qtr_end ---- only opps closing from the given quarter\n",
    "AND   a.dt >= (SELECT qtr_start\n",
    "             FROM src_config.zoom_quarter_mapping\n",
    "             WHERE CURRENT_DATE BETWEEN qtr_start AND qtr_end)\n",
    "GROUP BY 1,\n",
    "         2,\n",
    "         3,\n",
    "         4),\n",
    "         \n",
    "b AS\n",
    "---- QTD bookings\n",
    "(SELECT booking_date__c as dt,\n",
    "       fy_quarter,\n",
    "       case when sales_div_clean is null then 'UnDefined' else sales_div_clean end as sales_div,\n",
    "       SUM(bookings) OVER (PARTITION BY fy_quarter, sales_div_clean ORDER BY booking_date__c ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS bookings_qtd\n",
    "FROM (SELECT a.booking_date__c,\n",
    "             b.fy_quarter,\n",
    "             c.sales_div_clean,\n",
    "             SUM(Amount__c) AS bookings\n",
    "      FROM src_sfdc.bookings a\n",
    "        LEFT JOIN src_config.zoom_quarter_mapping b\n",
    "               ON a.booking_date__c BETWEEN b.qtr_start\n",
    "              AND b.qtr_end\n",
    "        LEFT JOIN lab.dw_20190311_sales_owner_division_clean_up_intl_as_one c ON a.owner_division__c = c.sales_div_dirty\n",
    "      WHERE 1 = 1\n",
    "      AND   isdeleted = FALSE\n",
    "      AND   ((Order_Type__c IN ('New','New Order') AND Amount__c >= 17) \n",
    "            OR (Order_Type__c = 'Upsell' AND Amount__c >= 0) \n",
    "            OR (Order_Type__c IN ('New','New Order') AND Amount__c < 17 AND Coupon__c <> '' AND coupon__c IS NOT NULL) \n",
    "            OR (bookingexception__c = 'Y'))\n",
    "      AND   LOWER(owner_name) NOT LIKE '%integration%'\n",
    "      AND   account__c <> ''\n",
    "      AND   account__c IS NOT NULL\n",
    "      AND   a.booking_date__c >= '2018-02-01'\n",
    "      AND   a.booking_date__c >= (SELECT qtr_start\n",
    "                                FROM src_config.zoom_quarter_mapping\n",
    "                                WHERE CURRENT_DATE BETWEEN qtr_start AND qtr_end)\n",
    "      GROUP BY 1,\n",
    "               2,\n",
    "               3)\n",
    "ORDER BY 3,1),\n",
    "\n",
    "c AS\n",
    "---- Bookings total for the quarter\n",
    "(SELECT b.fy_quarter,\n",
    "       case when c.sales_div_clean is null then 'UnDefined' else c.sales_div_clean end as sales_div,\n",
    "       SUM(Amount__c) AS direct_bookings\n",
    "FROM src_sfdc.bookings a\n",
    "  LEFT JOIN src_config.zoom_quarter_mapping b\n",
    "         ON a.booking_date__c BETWEEN b.qtr_start\n",
    "        AND b.qtr_end\n",
    "  LEFT JOIN lab.dw_20190311_sales_owner_division_clean_up_intl_as_one c ON a.owner_division__c = c.sales_div_dirty\n",
    "WHERE 1 = 1\n",
    "AND   isdeleted = FALSE\n",
    "AND   ((Order_Type__c IN ('New','New Order') AND Amount__c >= 17) \n",
    "      OR (Order_Type__c = 'Upsell' AND Amount__c >= 0) \n",
    "      OR (Order_Type__c IN ('New','New Order') AND Amount__c < 17 AND Coupon__c <> '' AND coupon__c IS NOT NULL) \n",
    "      OR (bookingexception__c = 'Y'))\n",
    "AND   lower(owner_name) NOT LIKE '%integration%'\n",
    "AND   account__c <> ''\n",
    "AND   account__c IS NOT NULL\n",
    "AND   a.booking_date__c >= '2018-02-01'\n",
    "AND   a.booking_date__c >= (SELECT qtr_start\n",
    "                          FROM src_config.zoom_quarter_mapping\n",
    "                          WHERE CURRENT_DATE BETWEEN qtr_start AND qtr_end)\n",
    "GROUP BY 1,2\n",
    "ORDER BY 1,2),\n",
    "\n",
    "d AS\n",
    "(SELECT b.fy_quarter,\n",
    "       case when c.sales_div_clean is null then 'UnDefined' else c.sales_div_clean end as sales_div,\n",
    "       SUM(quota__c) AS quota\n",
    "FROM src_sfdc.quota a\n",
    "  LEFT JOIN src_config.zoom_quarter_mapping b ON a.start_date__c::date = b.qtr_start\n",
    "  LEFT JOIN lab.dw_20190311_sales_owner_division_clean_up_intl_as_one c ON a.email__c = c.sales_div_dirty\n",
    "WHERE quota_owner_type__c = 'Segment'\n",
    "and quota__c > 0\n",
    "GROUP BY 1,2)\n",
    "\n",
    "SELECT a.dt,\n",
    "       a.fy_quarter,\n",
    "       a.day_of_qtr,\n",
    "       a.sales_div,\n",
    "       d.quota,\n",
    "       a.stage_1_count,\n",
    "       a.stage_1_amount,\n",
    "       a.stage_2_count,\n",
    "       a.stage_2_amount,\n",
    "       a.stage_3_count,\n",
    "       a.stage_3_amount,\n",
    "       a.stage_4_count,\n",
    "       a.stage_4_amount,\n",
    "       a.stage_5_count,\n",
    "       a.stage_5_amount,\n",
    "       CASE WHEN b.bookings_qtd IS NULL AND MAX(b.bookings_qtd) OVER (PARTITION BY a.fy_quarter, a.sales_div ORDER BY a.sales_div, a.dt ROWS BETWEEN 30 PRECEDING AND CURRENT ROW) IS NULL THEN 0\n",
    "            WHEN b.bookings_qtd IS NULL THEN MAX(b.bookings_qtd) OVER (PARTITION BY a.fy_quarter, a.sales_div ORDER BY a.sales_div, a.dt ROWS BETWEEN 30 PRECEDING AND CURRENT ROW) \n",
    "            ELSE b.bookings_qtd END as bookings_qtd,\n",
    "       c.direct_bookings,\n",
    "       case when a.fy_quarter like '%Q1' then a.day_of_qtr::float / 89 else a.day_of_qtr::float / 92 end as qtr_pct,\n",
    "       a.stage_1_amount / d.quota AS s1_quota_ratio,\n",
    "       a.stage_2_amount / d.quota AS s2_quota_ratio,\n",
    "       a.stage_3_amount / d.quota AS s3_quota_ratio,\n",
    "       a.stage_4_amount / d.quota AS s4_quota_ratio,\n",
    "       a.stage_5_amount / d.quota AS s5_quota_ratio,\n",
    "       (a.stage_1_amount + a.stage_2_amount + a.stage_3_amount + a.stage_4_amount + a.stage_5_amount +      \n",
    "            CASE WHEN b.bookings_qtd IS NULL AND MAX(b.bookings_qtd) OVER (PARTITION BY a.fy_quarter, a.sales_div ORDER BY a.sales_div, a.dt ROWS BETWEEN 30 PRECEDING AND CURRENT ROW) IS NULL THEN 0\n",
    "                 WHEN b.bookings_qtd IS NULL THEN MAX(b.bookings_qtd) OVER (PARTITION BY a.fy_quarter, a.sales_div ORDER BY a.sales_div, a.dt ROWS BETWEEN 30 PRECEDING AND CURRENT ROW) \n",
    "                 ELSE b.bookings_qtd END )/ d.quota AS s12345_bk_qtd_quota_ratio,\n",
    "       (a.stage_2_amount + a.stage_3_amount + a.stage_4_amount + a.stage_5_amount +      \n",
    "            CASE WHEN b.bookings_qtd IS NULL AND MAX(b.bookings_qtd) OVER (PARTITION BY a.fy_quarter, a.sales_div ORDER BY a.sales_div, a.dt ROWS BETWEEN 30 PRECEDING AND CURRENT ROW) IS NULL THEN 0\n",
    "                 WHEN b.bookings_qtd IS NULL THEN MAX(b.bookings_qtd) OVER (PARTITION BY a.fy_quarter, a.sales_div ORDER BY a.sales_div, a.dt ROWS BETWEEN 30 PRECEDING AND CURRENT ROW) \n",
    "                 ELSE b.bookings_qtd END )/ d.quota AS s2345_bk_qtd_quota_ratio,\n",
    "       (a.stage_3_amount + a.stage_4_amount + a.stage_5_amount +      \n",
    "            CASE WHEN b.bookings_qtd IS NULL AND MAX(b.bookings_qtd) OVER (PARTITION BY a.fy_quarter, a.sales_div ORDER BY a.sales_div, a.dt ROWS BETWEEN 30 PRECEDING AND CURRENT ROW) IS NULL THEN 0\n",
    "                 WHEN b.bookings_qtd IS NULL THEN MAX(b.bookings_qtd) OVER (PARTITION BY a.fy_quarter, a.sales_div ORDER BY a.sales_div, a.dt ROWS BETWEEN 30 PRECEDING AND CURRENT ROW) \n",
    "                 ELSE b.bookings_qtd END )/ d.quota AS s345_bk_qtd_quota_ratio,\n",
    "       (a.stage_4_amount + a.stage_5_amount +      \n",
    "            CASE WHEN b.bookings_qtd IS NULL AND MAX(b.bookings_qtd) OVER (PARTITION BY a.fy_quarter, a.sales_div ORDER BY a.sales_div, a.dt ROWS BETWEEN 30 PRECEDING AND CURRENT ROW) IS NULL THEN 0\n",
    "                 WHEN b.bookings_qtd IS NULL THEN MAX(b.bookings_qtd) OVER (PARTITION BY a.fy_quarter, a.sales_div ORDER BY a.sales_div, a.dt ROWS BETWEEN 30 PRECEDING AND CURRENT ROW) \n",
    "                 ELSE b.bookings_qtd END )/ d.quota AS s45_bk_qtd_quota_ratio,\n",
    "       (a.stage_5_amount +      \n",
    "            CASE WHEN b.bookings_qtd IS NULL AND MAX(b.bookings_qtd) OVER (PARTITION BY a.fy_quarter, a.sales_div ORDER BY a.sales_div, a.dt ROWS BETWEEN 30 PRECEDING AND CURRENT ROW) IS NULL THEN 0\n",
    "                 WHEN b.bookings_qtd IS NULL THEN MAX(b.bookings_qtd) OVER (PARTITION BY a.fy_quarter, a.sales_div ORDER BY a.sales_div, a.dt ROWS BETWEEN 30 PRECEDING AND CURRENT ROW) \n",
    "                 ELSE b.bookings_qtd END )/ d.quota AS s5_bk_qtd_quota_ratio,\n",
    "\n",
    "       (a.stage345_large_deals / d.quota) AS s345_lg_deal_quota_ratio,\n",
    "       (a.stage45_large_deals / d.quota) AS s45_lg_deal_quota_ratio,\n",
    "       (a.stage5_large_deals / d.quota) AS s5_lg_deal_quota_ratio,\n",
    "\n",
    "       (CASE WHEN b.bookings_qtd IS NULL AND MAX(b.bookings_qtd) OVER (PARTITION BY a.fy_quarter, a.sales_div ORDER BY a.sales_div, a.dt ROWS BETWEEN 30 PRECEDING AND CURRENT ROW) IS NULL THEN 0\n",
    "                 WHEN b.bookings_qtd IS NULL THEN MAX(b.bookings_qtd) OVER (PARTITION BY a.fy_quarter, a.sales_div ORDER BY a.sales_div, a.dt ROWS BETWEEN 30 PRECEDING AND CURRENT ROW) \n",
    "                 ELSE b.bookings_qtd END ) / d.quota as bookings_pct_qtd,\n",
    "       c.direct_bookings / d.quota as bookings_pct_finish\n",
    "FROM a\n",
    "  LEFT JOIN b\n",
    "         ON a.dt = b.dt\n",
    "        AND a.sales_div = b.sales_div\n",
    "        AND a.fy_quarter = b.fy_quarter\n",
    "  LEFT JOIN c\n",
    "         ON a.sales_div = c.sales_div\n",
    "        AND a.fy_quarter = c.fy_quarter\n",
    "  LEFT JOIN d\n",
    "         ON a.sales_div = d.sales_div\n",
    "        AND a.fy_quarter = d.fy_quarter\n",
    "WHERE a.dt >= (SELECT qtr_start\n",
    "                          FROM src_config.zoom_quarter_mapping\n",
    "                          WHERE CURRENT_DATE BETWEEN qtr_start AND qtr_end)\n",
    "AND a.sales_div NOT IN ('Channel', 'ISV', 'Online Team', 'UnDefined', 'API')\n",
    "ORDER BY 4,1,2,3;'''\n",
    "raw_data = pd.read_sql_query(text(sql), engine)\n",
    "raw_data.to_csv(\"/Users/derekwang/Desktop/Python/Sales Forecast/data_testing_curr_quarter_intl_together.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['qtr_pct', 's12345_bk_qtd_quota_ratio', 's2345_bk_qtd_quota_ratio',\n",
      "       's345_bk_qtd_quota_ratio', 's45_bk_qtd_quota_ratio',\n",
      "       's5_bk_qtd_quota_ratio', 's345_lg_deal_quota_ratio',\n",
      "       's45_lg_deal_quota_ratio', 's5_lg_deal_quota_ratio', 'bookings_pct_qtd',\n",
      "       'sales_div_comm', 'sales_div_comm-vast', 'sales_div_ed',\n",
      "       'sales_div_ent', 'sales_div_gov', 'sales_div_healthcare',\n",
      "       'sales_div_intl', 'sales_div_intl-anz', 'sales_div_intl-apac',\n",
      "       'sales_div_intl-emea', 'sales_div_intl-uk', 'sales_div_majors',\n",
      "       'sales_div_network_alliance', 'sales_div_smb', 'sales_div_smb-vast'],\n",
      "      dtype='object')\n",
      "\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=3, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "\n",
      "DONE - rf\n",
      "\n",
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.1, loss='ls', max_depth=None,\n",
      "             max_features=None, max_leaf_nodes=None,\n",
      "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "             min_samples_leaf=4, min_samples_split=6,\n",
      "             min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "             n_iter_no_change=None, presort='auto', random_state=None,\n",
      "             subsample=1.0, tol=0.0001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False)\n",
      "\n",
      "DONE - gb\n"
     ]
    }
   ],
   "source": [
    "#### predict for current quarter ####\n",
    "\n",
    "# Load the current_quarter_data \n",
    "curr_data = pd.read_csv(\"/Users/derekwang/Desktop/Python/Sales Forecast/data_testing_curr_quarter.csv\")\n",
    "curr_data = curr_data.drop([curr_data.columns[0]] , axis='columns')\n",
    "\n",
    "# Define outcome\n",
    "outcomes_raw_c = curr_data[['bookings_pct_finish']]\n",
    "\n",
    "# Define features = removing outcome, dt, and fy_quarter label\n",
    "features_raw_c1 = curr_data.drop(['direct_bookings', 'bookings_pct_finish'], axis = 1)\n",
    "\n",
    "features_raw_c = features_raw_c1.drop(['dt', \n",
    "                                'fy_quarter', \n",
    "                                'day_of_qtr', \n",
    "                                'quota', \n",
    "                                'stage_1_count', \n",
    "                                'stage_1_amount', \n",
    "                                'stage_2_count', \n",
    "                                'stage_2_amount', \n",
    "                                'stage_3_count', \n",
    "                                'stage_3_amount', \n",
    "                                'stage_4_count', \n",
    "                                'stage_4_amount', \n",
    "                                'stage_5_count', \n",
    "                                'stage_5_amount', \n",
    "                                'bookings_qtd',\n",
    "                                's1_quota_ratio', 's2_quota_ratio', 's3_quota_ratio', 's4_quota_ratio','s5_quota_ratio'\n",
    "#                                       ,'sales_div'   \n",
    "                                      ], axis = 1)\n",
    "\n",
    "# fill in NA's with 0 - FEATURES\n",
    "features_c = features_raw_c.fillna(0.0)\n",
    "\n",
    "# fill in NA's with 0 - OUTCOMES\n",
    "outcomes_c = outcomes_raw_c.fillna(0.0)\n",
    "\n",
    "# One-hot encoding\n",
    "X_curr = pd.get_dummies(features_c)\n",
    "\n",
    "# get rid of blanks in headers\n",
    "X_curr.columns = X_curr.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "\n",
    "print(X_curr.columns)\n",
    "\n",
    "models = [rf, gb]\n",
    "for x in models:\n",
    "    print(\"\")\n",
    "    print(x)\n",
    "    y_curr = x.predict(X_curr)\n",
    "    y_curr = y_curr.flatten()\n",
    "    y_curr = pd.DataFrame(y_curr)\n",
    "    # export prediciton\n",
    "    dfc = pd.concat([features_raw_c1.reset_index(), y_curr.reset_index()], axis=1)\n",
    "    if x == rf:\n",
    "#         dfc.to_csv(\"/Users/derekwang/Desktop/Python/Sales Forecast/curr_quarter_prediction__2_random_forest_\" + str(date.today()) + \".csv\", sep=',')\n",
    "        writer = ExcelWriter(\"/Users/derekwang/Desktop/Python/Sales Forecast/curr_quarter_prediction__2_random_forest_\" + str(date.today()) + \".xlsx\")\n",
    "        dfc.to_excel(writer,'Sheet1')\n",
    "        writer.save()\n",
    "        print(\"\")\n",
    "        print(\"DONE - rf\")\n",
    "    if x == gb:\n",
    "#         dfc.to_csv(\"/Users/derekwang/Desktop/Python/Sales Forecast/curr_quarter_prediction__3_gradient_boost_\" + str(date.today()) + \".csv\", sep=',')\n",
    "        writer = ExcelWriter(\"/Users/derekwang/Desktop/Python/Sales Forecast/curr_quarter_prediction__3_gradient_boost_\" + str(date.today()) + \".xlsx\")\n",
    "        dfc.to_excel(writer,'Sheet1')\n",
    "        writer.save()\n",
    "        print(\"\")\n",
    "        print(\"DONE - gb\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['qtr_pct', 's12345_bk_qtd_quota_ratio', 's2345_bk_qtd_quota_ratio',\n",
      "       's345_bk_qtd_quota_ratio', 's45_bk_qtd_quota_ratio',\n",
      "       's5_bk_qtd_quota_ratio', 's345_lg_deal_quota_ratio',\n",
      "       's45_lg_deal_quota_ratio', 's5_lg_deal_quota_ratio', 'bookings_pct_qtd',\n",
      "       'sales_div_comm', 'sales_div_comm-vast', 'sales_div_ed',\n",
      "       'sales_div_ent', 'sales_div_gov', 'sales_div_healthcare',\n",
      "       'sales_div_intl', 'sales_div_majors', 'sales_div_network_alliance',\n",
      "       'sales_div_smb', 'sales_div_smb-vast'],\n",
      "      dtype='object')\n",
      "\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=3, min_samples_split=5,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "\n",
      "DONE - rf_int_t\n",
      "\n",
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.1, loss='ls', max_depth=None,\n",
      "             max_features=None, max_leaf_nodes=None,\n",
      "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "             min_samples_leaf=3, min_samples_split=3,\n",
      "             min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "             n_iter_no_change=None, presort='auto', random_state=None,\n",
      "             subsample=1.0, tol=0.0001, validation_fraction=0.1, verbose=0,\n",
      "             warm_start=False)\n",
      "\n",
      "DONE - gb_int_t\n"
     ]
    }
   ],
   "source": [
    "#### predict for current quarter ####\n",
    "\n",
    "# Load the current_quarter_data \n",
    "curr_data = pd.read_csv(\"/Users/derekwang/Desktop/Python/Sales Forecast/data_testing_curr_quarter_intl_together.csv\")\n",
    "curr_data = curr_data.drop([curr_data.columns[0]] , axis='columns')\n",
    "\n",
    "# Define outcome\n",
    "outcomes_raw_c = curr_data[['bookings_pct_finish']]\n",
    "\n",
    "# Define features = removing outcome, dt, and fy_quarter label\n",
    "features_raw_c1 = curr_data.drop(['direct_bookings', 'bookings_pct_finish'], axis = 1)\n",
    "\n",
    "features_raw_c = features_raw_c1.drop(['dt', \n",
    "                                'fy_quarter', \n",
    "                                'day_of_qtr', \n",
    "                                'quota', \n",
    "                                'stage_1_count', \n",
    "                                'stage_1_amount', \n",
    "                                'stage_2_count', \n",
    "                                'stage_2_amount', \n",
    "                                'stage_3_count', \n",
    "                                'stage_3_amount', \n",
    "                                'stage_4_count', \n",
    "                                'stage_4_amount', \n",
    "                                'stage_5_count', \n",
    "                                'stage_5_amount', \n",
    "                                'bookings_qtd',\n",
    "                                's1_quota_ratio', 's2_quota_ratio', 's3_quota_ratio', 's4_quota_ratio','s5_quota_ratio'\n",
    "#                                       ,'sales_div'   \n",
    "                                      ], axis = 1)\n",
    "\n",
    "# fill in NA's with 0 - FEATURES\n",
    "features_c = features_raw_c.fillna(0.0)\n",
    "\n",
    "# fill in NA's with 0 - OUTCOMES\n",
    "# outcomes_c = outcomes_raw_c.fillna(0.0)\n",
    "\n",
    "# One-hot encoding\n",
    "X_curr = pd.get_dummies(features_c)\n",
    "\n",
    "# get rid of blanks in headers\n",
    "X_curr.columns = X_curr.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "\n",
    "print(X_curr.columns)\n",
    "\n",
    "\n",
    "\n",
    "models = [rf_int_t, gb_int_t]\n",
    "for x in models:\n",
    "    print(\"\")\n",
    "    print(x)\n",
    "    y_curr = x.predict(X_curr)\n",
    "    y_curr = y_curr.flatten()\n",
    "    y_curr = pd.DataFrame(y_curr)\n",
    "    # export prediciton\n",
    "    dfc = pd.concat([features_raw_c1.reset_index(), y_curr.reset_index()], axis=1)\n",
    "    if x == rf_int_t:\n",
    "#         dfc.to_csv(\"/Users/derekwang/Desktop/Python/Sales Forecast/curr_quarter_prediction__4_random_forest_intl_together_\" + str(date.today()) + \".csv\", sep=',')\n",
    "        writer = ExcelWriter(\"/Users/derekwang/Desktop/Python/Sales Forecast/curr_quarter_prediction__4_random_forest_intl_together_\" + str(date.today()) + \".xlsx\")\n",
    "        dfc.to_excel(writer,'Sheet1')\n",
    "        writer.save()\n",
    "        print(\"\")\n",
    "        print(\"DONE - rf_int_t\")\n",
    "    if x == gb_int_t:\n",
    "#         dfc.to_csv(\"/Users/derekwang/Desktop/Python/Sales Forecast/curr_quarter_prediction__5_gradient_boost_intl_together_\" + str(date.today()) + \".csv\", sep=',')\n",
    "        writer = ExcelWriter(\"/Users/derekwang/Desktop/Python/Sales Forecast/curr_quarter_prediction__5_gradient_boost_intl_together_\" + str(date.today()) + \".xlsx\")\n",
    "        dfc.to_excel(writer,'Sheet1')\n",
    "        writer.save()\n",
    "        print(\"\")\n",
    "        print(\"DONE - gb_int_t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
